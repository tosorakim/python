{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4장코드_디버깅_이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다른사람이 짠 코드 볼때 하나하나씩 디버깅하는게 중요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설명1. 필요한 패키지를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망이 생성되었습니다\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W2': array([[-1.39861483e-02, -2.10773749e-02,  1.98471011e-02,\n",
       "         -2.36327725e-03, -5.29544406e-03,  2.49337085e-02,\n",
       "         -5.06294381e-03,  1.37596986e-03,  7.46235722e-03,\n",
       "         -5.83394840e-03],\n",
       "        [-1.46029407e-02, -2.06978178e-02,  1.96719170e-02,\n",
       "         -8.86376351e-04, -5.78475761e-03,  2.37709104e-02,\n",
       "         -8.36748525e-03,  2.48546276e-03,  9.07517090e-03,\n",
       "         -4.66408336e-03],\n",
       "        [-1.70258828e-02, -2.17331758e-02,  1.97289574e-02,\n",
       "         -2.78488198e-03, -4.40054229e-03,  2.62067263e-02,\n",
       "         -5.52057638e-03,  2.39781519e-03,  8.23259713e-03,\n",
       "         -5.10103672e-03],\n",
       "        [-1.35932811e-02, -2.14369948e-02,  1.93232133e-02,\n",
       "         -1.21660615e-03, -3.32112575e-03,  2.34264561e-02,\n",
       "         -5.28221570e-03,  4.99296102e-04,  7.53253824e-03,\n",
       "         -5.93128028e-03],\n",
       "        [-1.68337419e-02, -2.18591956e-02,  1.94040864e-02,\n",
       "         -2.49090617e-03, -4.96043923e-03,  2.61648404e-02,\n",
       "         -4.91425424e-03,  2.09181372e-03,  7.94861256e-03,\n",
       "         -4.55081594e-03],\n",
       "        [-1.55607850e-02, -2.15676378e-02,  2.11591531e-02,\n",
       "         -1.28931666e-03, -4.12183806e-03,  2.58784619e-02,\n",
       "         -6.84916777e-03,  1.50400080e-03,  6.21958582e-03,\n",
       "         -5.37245632e-03],\n",
       "        [-1.68192892e-02, -2.16609851e-02,  1.98189299e-02,\n",
       "         -2.50007904e-03, -2.26256214e-03,  2.65676403e-02,\n",
       "         -6.84740079e-03,  2.17022315e-03,  7.08881419e-03,\n",
       "         -5.55529132e-03],\n",
       "        [-1.64572228e-02, -2.19403665e-02,  2.00015622e-02,\n",
       "         -1.31605871e-03, -2.79543558e-03,  2.48041509e-02,\n",
       "         -5.18357610e-03,  2.22792975e-03,  6.64403004e-03,\n",
       "         -5.98501314e-03],\n",
       "        [-1.45557469e-02, -1.98330973e-02,  1.94454447e-02,\n",
       "         -2.11214796e-03, -5.28720292e-03,  2.56690804e-02,\n",
       "         -5.38030048e-03, -6.87639459e-05,  8.95472651e-03,\n",
       "         -6.83199206e-03],\n",
       "        [-1.59205804e-02, -2.30709386e-02,  1.99321539e-02,\n",
       "         -1.13379253e-03, -3.70735700e-03,  2.61265309e-02,\n",
       "         -7.80819524e-03,  1.73541443e-03,  8.32894287e-03,\n",
       "         -4.48217829e-03],\n",
       "        [-1.67723947e-02, -1.99547501e-02,  1.96427591e-02,\n",
       "         -7.97074007e-04, -4.21225301e-03,  2.53517568e-02,\n",
       "         -6.72222067e-03,  9.89612426e-04,  8.25344328e-03,\n",
       "         -5.77887902e-03],\n",
       "        [-1.83426063e-02, -1.89336588e-02,  1.88078982e-02,\n",
       "          5.22066344e-04, -4.04110611e-03,  2.52589441e-02,\n",
       "         -4.96901247e-03,  8.14024235e-04,  5.83447416e-03,\n",
       "         -4.95102338e-03],\n",
       "        [-1.46362439e-02, -2.31409471e-02,  1.97003239e-02,\n",
       "         -1.28464933e-03, -5.40923960e-03,  2.60978207e-02,\n",
       "         -6.70664594e-03,  1.81310251e-03,  8.40565478e-03,\n",
       "         -4.83917599e-03],\n",
       "        [-1.51844345e-02, -2.12061907e-02,  1.92660840e-02,\n",
       "         -2.60398327e-05, -4.54701489e-03,  2.44780488e-02,\n",
       "         -6.75442352e-03,  1.17467916e-03,  8.58426348e-03,\n",
       "         -5.78497199e-03],\n",
       "        [-1.66121851e-02, -2.07097876e-02,  1.97659517e-02,\n",
       "         -1.80009674e-03, -4.49015722e-03,  2.62501216e-02,\n",
       "         -7.88655849e-03,  2.41341179e-03,  8.10754001e-03,\n",
       "         -5.03823995e-03],\n",
       "        [-1.16371114e-02, -2.63506272e-02,  2.00429681e-02,\n",
       "         -1.71156794e-03, -3.50430546e-03,  2.53124242e-02,\n",
       "         -3.24139055e-03,  7.85573973e-06,  6.66866447e-03,\n",
       "         -5.58690996e-03],\n",
       "        [-1.63222169e-02, -1.99942293e-02,  1.99773315e-02,\n",
       "         -3.63825566e-03, -4.34577150e-03,  2.57420494e-02,\n",
       "         -5.91419192e-03,  1.32556582e-03,  7.58442203e-03,\n",
       "         -4.41470351e-03],\n",
       "        [-1.58076945e-02, -2.06727249e-02,  1.94117989e-02,\n",
       "         -1.75540467e-03, -4.48916983e-03,  2.44172490e-02,\n",
       "         -5.91950951e-03,  1.82754885e-03,  7.93262560e-03,\n",
       "         -4.94471902e-03],\n",
       "        [-1.51614925e-02, -2.12123344e-02,  2.05877053e-02,\n",
       "         -5.13682137e-04, -4.34283226e-03,  2.44452020e-02,\n",
       "         -6.19116839e-03, -1.80124537e-04,  7.30100695e-03,\n",
       "         -4.73228007e-03],\n",
       "        [-1.39906970e-02, -2.03018154e-02,  2.05719267e-02,\n",
       "         -1.27892314e-03, -5.17230057e-03,  2.51364799e-02,\n",
       "         -4.69978890e-03,  1.06851601e-03,  6.19465240e-03,\n",
       "         -7.52804998e-03],\n",
       "        [-1.77417902e-02, -1.83419351e-02,  1.95055541e-02,\n",
       "         -3.31327088e-03, -3.03835657e-03,  2.39480868e-02,\n",
       "         -4.75427771e-03,  1.09858557e-03,  6.98983385e-03,\n",
       "         -4.35242994e-03],\n",
       "        [-1.35020432e-02, -2.15059681e-02,  1.87850289e-02,\n",
       "         -1.02236551e-03, -4.24071393e-03,  2.35222121e-02,\n",
       "         -5.95188392e-03,  8.18966855e-04,  8.47444255e-03,\n",
       "         -5.37767583e-03],\n",
       "        [-1.22565108e-02, -2.22684079e-02,  1.85616585e-02,\n",
       "         -2.03052757e-03, -3.95663241e-03,  2.37392727e-02,\n",
       "         -8.07720710e-03,  3.47138713e-03,  7.43436799e-03,\n",
       "         -4.61740064e-03],\n",
       "        [-1.64017852e-02, -2.23259242e-02,  1.95091388e-02,\n",
       "         -1.98192505e-04, -3.42822058e-03,  2.70961697e-02,\n",
       "         -6.55359618e-03,  1.47438699e-03,  7.93727067e-03,\n",
       "         -7.10924756e-03],\n",
       "        [-1.68289724e-02, -2.16113276e-02,  1.99303520e-02,\n",
       "         -2.43549729e-03, -4.75569402e-03,  2.49348315e-02,\n",
       "         -3.82181028e-03,  1.95477726e-03,  7.22395449e-03,\n",
       "         -4.59061352e-03],\n",
       "        [-1.64233340e-02, -2.12588467e-02,  1.98466643e-02,\n",
       "         -1.63986111e-03, -3.11594164e-03,  2.76049766e-02,\n",
       "         -8.72144798e-03,  1.99112517e-03,  7.25443627e-03,\n",
       "         -5.53777100e-03],\n",
       "        [-1.68320326e-02, -1.94221330e-02,  2.06005846e-02,\n",
       "         -4.40185559e-03, -4.28006768e-03,  2.65232918e-02,\n",
       "         -4.78745357e-03,  1.00704955e-03,  8.17263496e-03,\n",
       "         -6.58001846e-03],\n",
       "        [-1.54469052e-02, -2.11733012e-02,  2.01899837e-02,\n",
       "         -2.00716297e-03, -5.17412323e-03,  2.52824285e-02,\n",
       "         -4.43762661e-03,  1.17905989e-03,  8.45673407e-03,\n",
       "         -6.86908700e-03],\n",
       "        [-1.49803822e-02, -2.27102299e-02,  2.06667745e-02,\n",
       "         -2.63535632e-03, -3.26970502e-03,  2.83335515e-02,\n",
       "         -8.41744725e-03,  1.27168961e-03,  8.25599738e-03,\n",
       "         -6.51489229e-03],\n",
       "        [-1.58402415e-02, -2.16530285e-02,  1.96353824e-02,\n",
       "         -2.67811176e-03, -3.39382737e-03,  2.41090447e-02,\n",
       "         -4.28248336e-03,  2.05712629e-03,  7.10551787e-03,\n",
       "         -5.05937877e-03],\n",
       "        [-1.36348559e-02, -2.08151282e-02,  1.88138366e-02,\n",
       "         -2.72940066e-04, -4.52607600e-03,  2.28891294e-02,\n",
       "         -7.35894482e-03,  1.12745758e-03,  8.38012625e-03,\n",
       "         -4.60260482e-03],\n",
       "        [-1.70041468e-02, -2.07602118e-02,  1.98739016e-02,\n",
       "         -2.15258190e-03, -3.63386516e-03,  2.64826100e-02,\n",
       "         -6.75005928e-03,  1.47891940e-03,  7.74568627e-03,\n",
       "         -5.28025232e-03],\n",
       "        [-1.27638330e-02, -2.06972121e-02,  1.91848557e-02,\n",
       "         -9.96996734e-04, -4.04368816e-03,  2.43464419e-02,\n",
       "         -6.55463441e-03,  1.20757350e-05,  7.57459077e-03,\n",
       "         -6.06159965e-03],\n",
       "        [-1.42161339e-02, -2.30059326e-02,  2.04277074e-02,\n",
       "         -2.57137438e-03, -3.36803672e-03,  2.71358928e-02,\n",
       "         -6.93553469e-03,  1.22705734e-03,  7.79954259e-03,\n",
       "         -6.49318790e-03],\n",
       "        [-1.44042003e-02, -2.09273283e-02,  1.96624235e-02,\n",
       "         -2.97595978e-03, -2.62159266e-03,  2.57335881e-02,\n",
       "         -6.93977933e-03,  1.84074225e-03,  7.39068844e-03,\n",
       "         -6.75858186e-03],\n",
       "        [-1.72635340e-02, -2.16015172e-02,  2.13912802e-02,\n",
       "         -4.64939208e-03, -3.61061972e-03,  2.76991989e-02,\n",
       "         -5.11324144e-03,  8.44820576e-04,  7.82091629e-03,\n",
       "         -5.51791160e-03],\n",
       "        [-1.89713874e-02, -1.96277148e-02,  2.09723594e-02,\n",
       "         -2.55367962e-03, -3.84201890e-03,  2.75390888e-02,\n",
       "         -6.34834897e-03,  7.22547404e-04,  9.10087053e-03,\n",
       "         -6.99171639e-03],\n",
       "        [-1.56902632e-02, -2.16748193e-02,  1.97349736e-02,\n",
       "         -2.94475494e-03, -2.98061508e-03,  2.64968693e-02,\n",
       "         -6.60059489e-03,  1.43305775e-03,  7.72136451e-03,\n",
       "         -5.49521771e-03],\n",
       "        [-1.98398990e-02, -2.11041913e-02,  2.06718950e-02,\n",
       "         -4.28869758e-03, -1.59653423e-03,  2.71469770e-02,\n",
       "         -7.65416827e-03,  4.10785377e-03,  7.49894095e-03,\n",
       "         -4.94217638e-03],\n",
       "        [-1.45841877e-02, -1.86423283e-02,  1.93468276e-02,\n",
       "         -3.48523379e-03, -4.91196748e-03,  2.38817179e-02,\n",
       "         -7.84337522e-03,  2.49223564e-03,  8.23388951e-03,\n",
       "         -4.48757811e-03],\n",
       "        [-1.42151787e-02, -2.19279555e-02,  2.02236245e-02,\n",
       "         -2.07460187e-03, -4.33390863e-03,  2.64253498e-02,\n",
       "         -8.10211814e-03,  2.23178686e-03,  7.49863457e-03,\n",
       "         -5.72563278e-03],\n",
       "        [-1.24200732e-02, -2.26263476e-02,  2.06076199e-02,\n",
       "         -2.76311628e-03, -4.20873837e-03,  2.46156860e-02,\n",
       "         -3.32725398e-03, -1.89516020e-04,  7.01768493e-03,\n",
       "         -6.70594538e-03],\n",
       "        [-1.48138858e-02, -2.19981105e-02,  2.11904061e-02,\n",
       "         -7.76977103e-04, -3.96531419e-03,  2.48960490e-02,\n",
       "         -5.73649109e-03,  5.74421601e-05,  7.58154803e-03,\n",
       "         -6.43466668e-03],\n",
       "        [-1.52267225e-02, -2.34638242e-02,  2.10140964e-02,\n",
       "         -2.13866525e-03, -3.84591331e-03,  2.65047045e-02,\n",
       "         -7.66906151e-03,  3.21574936e-03,  6.12931259e-03,\n",
       "         -4.51967601e-03],\n",
       "        [-1.48494728e-02, -2.19026603e-02,  1.99712364e-02,\n",
       "         -3.40396532e-03, -3.99947908e-03,  2.45921752e-02,\n",
       "         -3.56361150e-03,  3.99678080e-04,  8.76262193e-03,\n",
       "         -6.00652262e-03],\n",
       "        [-1.33506791e-02, -2.07011374e-02,  1.85435823e-02,\n",
       "         -2.17341833e-03, -5.15955566e-03,  2.45338025e-02,\n",
       "         -6.62476580e-03,  1.13006034e-03,  8.90482949e-03,\n",
       "         -5.10271835e-03],\n",
       "        [-1.68027632e-02, -2.22241046e-02,  1.98106998e-02,\n",
       "         -4.16557282e-03, -3.33886995e-03,  2.47030673e-02,\n",
       "         -3.28312030e-03,  1.59530046e-03,  8.14206859e-03,\n",
       "         -4.43670523e-03],\n",
       "        [-1.16420261e-02, -2.23053358e-02,  2.00882402e-02,\n",
       "         -1.71975997e-03, -5.19317138e-03,  2.39321325e-02,\n",
       "         -5.80123012e-03,  1.58690118e-03,  7.14430616e-03,\n",
       "         -6.09005671e-03],\n",
       "        [-1.71005169e-02, -2.27779432e-02,  1.99900597e-02,\n",
       "         -1.64836223e-03, -3.45342916e-03,  2.69681919e-02,\n",
       "         -5.90283481e-03,  1.58311017e-03,  7.97947384e-03,\n",
       "         -5.63774932e-03],\n",
       "        [-1.45845922e-02, -2.21546719e-02,  2.07432647e-02,\n",
       "         -2.21157720e-03, -3.48567893e-03,  2.43689736e-02,\n",
       "         -5.68697246e-03,  9.87461581e-04,  7.16033744e-03,\n",
       "         -5.13654459e-03]]),\n",
       " 'b2': array([-0.03005284, -0.04279452,  0.03957879, -0.00503311, -0.00794424,\n",
       "         0.05067454, -0.01177738,  0.00303261,  0.0155379 , -0.01122174]),\n",
       " 'W1': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'b1': array([-4.43872010e-05, -1.28953938e-04,  1.08883721e-04,  6.99586154e-05,\n",
       "        -6.16345074e-04,  3.79689267e-04,  2.62343581e-04, -8.34115731e-05,\n",
       "         1.31887862e-04,  2.72389362e-05, -3.98994470e-05, -1.56074255e-05,\n",
       "         2.56221729e-04,  2.21679511e-04,  2.34733757e-04, -1.02606951e-05,\n",
       "        -3.70974140e-05, -6.31765015e-05,  1.48309048e-04, -3.26213793e-04,\n",
       "         2.22294821e-05,  8.47705466e-05,  3.60188619e-04, -3.63192312e-04,\n",
       "         1.37101862e-05, -7.45058779e-05,  4.08542589e-04,  4.29603665e-05,\n",
       "         3.71151914e-05, -1.26903988e-04, -4.00370850e-05, -2.19368184e-04,\n",
       "         4.57510545e-05,  4.68497301e-04, -5.18632640e-05, -3.55519605e-04,\n",
       "        -4.34962332e-04,  1.94375906e-04, -1.27398075e-05, -4.18670346e-04,\n",
       "        -3.76605169e-06, -2.44727160e-05, -1.34926404e-04, -4.57928637e-04,\n",
       "         1.05570891e-04,  4.09681630e-04,  1.45037362e-04,  1.52170679e-04,\n",
       "         2.27459019e-04, -5.33089840e-05])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TwoLayerNet:\n",
    "##1. 가중치행렬 W1, W2, b1, b2를 구성합니다.\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        print('신경망이 생성되었습니다')\n",
    "\n",
    "#network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) #network 객체\n",
    "#network.params.keysy() #가중치 행렬을 가지고 있는 params 딕셔너리의 키값들을 확인할 수 있음\n",
    "#network.params['W1'] #딕셔너리 벨류값볼때 대괄호해주면 볼 수 있음\n",
    "#network.params['W1'].shape #(784, 50)\n",
    "#network.params['W2'].shape #(784, 50)\n",
    "#network.params['b1'].shape #(784, 50)\n",
    "#network.params['b2'].shape #(784, 50)\n",
    "\n",
    "#2. 입력데이터(필기체)를 넣고 1층과 2층을 거쳐서 확률벡터를 출력하는 함수\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2'] #가중치 불러오는 코드\n",
    "        b1, b2 = self.params['b1'], self.params['b2'] #바이어스 불러오는 코드\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "#network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) #network 객체\n",
    "#(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "#network.predict(x_train).shape #(60000, 10)\n",
    "\n",
    "#3. 오차(에러)를 출력하는 함수\n",
    "\n",
    "      \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t) #오차가 하나만 나오는지 디버깅 해보겠습니다.\n",
    "\n",
    "#network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) #network 객체\n",
    "#(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "#network.loss(x_train[100], t_train[100]) #loss를 구할때 두 항목을 넣습니다.\n",
    "\n",
    "#4. 정확도를 출력하는 함수\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x) #predict을 하면 확률벡터가 나옴\n",
    "        y = np.argmax(y, axis=1) #축을 기준으로 최대값(argmax)을 구해라\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "#network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) #network 객체\n",
    "#(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "#network.accuracy(x_train[:100,], t_train[:100,]) #100개만 가져오기[:100, ] ===> 0.1\n",
    "\n",
    "  \n",
    "#5. 편미분해서 기울기 출력하는 함수(4개의 기울기를 출력, W1, b1, W2, b2)\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t) #lambda 이름없는 한줄짜리 함수\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "#network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) #network 객체\n",
    "#(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "#network.numerical_gradient(x_train[:100,], t_train[:100,]) #100개값의 가중치값이 출력됨\n",
    "\n",
    "#6. 위의 수치미분은 너무느려서, 6만개 하려면... 못쓰고, 5장에서 배울 오차역전파를 써서 가중치를 갱신해줘야합니다\n",
    "#그럼 수치미분은 왜 배웠나? 원리를 이해하라고....!\n",
    "#지금 아래의 gradient는 5장에서 배울 오차역전파 함수입니다.\n",
    "#현업에서 쓰는 모든 오차함수는 \"오차역전파\"입니다. => 학습속도가 훨씬 빠릅니다.\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) #network 객체\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "network.gradient(x_train[:100,], t_train[:100,]) #지금은 기울기가 로딩없이 바로 나옵니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망이 생성되었습니다\n",
      "train acc, test acc | 0.10218333333333333, 0.101\n",
      "train acc, test acc | 0.7867333333333333, 0.7956\n",
      "train acc, test acc | 0.8788833333333333, 0.8843\n",
      "train acc, test acc | 0.8994, 0.9048\n",
      "train acc, test acc | 0.9076166666666666, 0.9119\n",
      "train acc, test acc | 0.9146666666666666, 0.9174\n",
      "train acc, test acc | 0.91925, 0.9204\n",
      "train acc, test acc | 0.9232666666666667, 0.9266\n",
      "train acc, test acc | 0.92795, 0.9292\n",
      "train acc, test acc | 0.93025, 0.9317\n",
      "train acc, test acc | 0.9335166666666667, 0.9341\n",
      "train acc, test acc | 0.9355666666666667, 0.936\n",
      "train acc, test acc | 0.93885, 0.9369\n",
      "train acc, test acc | 0.9408666666666666, 0.9391\n",
      "train acc, test acc | 0.9427166666666666, 0.9409\n",
      "train acc, test acc | 0.94485, 0.9428\n",
      "train acc, test acc | 0.9468, 0.9453\n",
      "train acc, test acc | 0.9485333333333333, 0.9462\n",
      "train acc, test acc | 0.94965, 0.946\n",
      "train acc, test acc | 0.9517666666666666, 0.9485\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#지금부터의 코드는 위에서 만든 클랙스를 객체화시키고 필기체 데이터를 불러와서\n",
    "#객체화시킨 신경망에 100개씩 입력해서 학습시키는 코드\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #정확도를 시각화하기 위해서 필요\n",
    "from dataset.mnist import load_mnist #필기체 데이터를 불러오는 코드\n",
    "#from two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 12000  # 반복 횟수를 적절히 설정한다. => 10에폭 돌게 설정\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1 #학습률\n",
    "\n",
    "train_loss_list = [] #오차를 담을 리스트(시각화를 위해서 데이터를 저장)\n",
    "train_acc_list = [] #훈련데이터의 정확도를 담을 리스트(시각화를 위해서 데이터를 저장)\n",
    "test_acc_list = [] #테스트 데이터의 정확도를 담을 리스트(시각화를 위해서 데이터를 저장)\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1) #60000 / 10 = 600\n",
    "# 1에폭당 정확도를 시각화하기 위해 필요한 코드입니다\n",
    "\n",
    "for i in range(iters_num): #i가 1부터 6000번 루프문 도는데,\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size) #(60000, 100) 0~60000미만 숫자 중 100개의 숫자를 랜덤추출\n",
    "    x_batch = x_train[batch_mask] #위의 100개 랜덤을 batch_mask에 담아서 훈련데이터로 만듬(100개)\n",
    "    t_batch = t_train[batch_mask] #훈련데이터의 정답 100개\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'): #가중치와 비어스를 갱신 => 1에폭 도는 동안 반복(학습)\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch) #오차를 담는다. 밑에서 사용하지는 않음.\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0: #1에폭 돌 때 아래의 코드를 실행해라\n",
    "        train_acc = network.accuracy(x_train, t_train) #훈련데이터의 정확도 출력 : 60,000개\n",
    "        test_acc = network.accuracy(x_test, t_test) #테스트 데이터 정확도 출력: 10,000개\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# 그래프 그리기 => 시각화해서 잘 돌았는지 확인을 위해서\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
